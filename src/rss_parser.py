import feedparser
import os
import sys
import requests
import re
from tqdm import tqdm
from typing import List, Dict, Optional, Union

# --- 1. ç’°å¢ƒè¨­å®šå€ (èˆ‡ transcriber.py å…±ç”¨é‚è¼¯) ---
def detect_environment():
    """åµæ¸¬æ˜¯å¦åœ¨ Colab ç’°å¢ƒ"""
    return "COLAB_RELEASE_TAG" in os.environ or 'google.colab' in sys.modules

def get_project_root():
    """å›å‚³å°ˆæ¡ˆæ ¹ç›®éŒ„"""
    if detect_environment():
        # Colab è·¯å¾‘
        root = '/content/drive/MyDrive/MyProject/whisper'
        # ç°¡å–®æª¢æŸ¥æ›è¼‰
        if not os.path.exists('/content/drive'):
            print("âš ï¸ Colab ç’°å¢ƒä½†æœªæª¢æ¸¬åˆ° Driveï¼Œè«‹ç¢ºä¿å·²åŸ·è¡Œ drive.mount()")
        return root
    else:
        # æœ¬åœ°è·¯å¾‘
        return os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# --- 2. æ ¸å¿ƒä¸‹è¼‰å™¨é¡åˆ¥ ---
class PodcastDownloader:
    def __init__(self, rss_url: str, sub_dir: str = "downloads"):
        """
        åˆå§‹åŒ– Podcast ä¸‹è¼‰å™¨
        :param rss_url: Podcast çš„ RSS Feed ç¶²å€
        :param sub_dir: å„²å­˜å­è³‡æ–™å¤¾åç¨± (ä¾‹å¦‚: "openhouse" æˆ– "gooaye")
        """
        self.rss_url = rss_url
        self.episodes = [] # å„²å­˜è§£æå¾Œçš„é›†æ•¸åˆ—è¡¨
        
        # è‡ªå‹•æ±ºå®šå„²å­˜è·¯å¾‘
        project_root = get_project_root()
        self.save_dir = os.path.join(project_root, "data", "audio", sub_dir)
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        if not os.path.exists(self.save_dir):
            os.makedirs(self.save_dir)
            print(f"ğŸ“‚ å»ºç«‹ç›®éŒ„: {self.save_dir}")
        else:
            print(f"ğŸ“‚ ä¸‹è¼‰ç›®éŒ„: {self.save_dir}")

    def parse_feed(self) -> List[Dict]:
        """è§£æ RSS Feed ä¸¦æå–é›†æ•¸è³‡è¨Š"""
        print(f"ğŸ“¡ æ­£åœ¨è§£æ RSS: {self.rss_url} ...")
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        try:
            response = requests.get(self.rss_url, headers=headers, timeout=15)
            response.raise_for_status()
            self.feed = feedparser.parse(response.content)
        except Exception as e:
            raise ValueError(f"âŒ ä¸‹è¼‰ RSS å¤±æ•—: {e}")

        channel_title = self.feed.feed.get('title', 'Unknown')
        print(f"âœ… é »é“åç¨±: {channel_title}")
        
        self.episodes = [] # é‡ç½®åˆ—è¡¨
        for entry in self.feed.entries:
            audio_url = None
            # å„ªå…ˆå¾ links æ‰¾ audio é¡å‹
            for link in entry.get('links', []):
                if link.get('type', '').startswith('audio'):
                    audio_url = link.get('href')
                    break
            
            # å‚™ç”¨ï¼šå¾ enclosures æ‰¾
            if not audio_url and 'enclosures' in entry:
                for enclosure in entry.enclosures:
                    if enclosure.get('type', '').startswith('audio'):
                        audio_url = enclosure.get('href')
                        break

            if audio_url:
                title = entry.get('title', 'No Title')
                
                # --- Regex æå–é›†æ•¸ ---
                # æ”¯æ´: EP418, ep 418, Ep.418
                ep_match = re.search(r"(?i)EP\.?\s*(\d+)", title)
                ep_number = int(ep_match.group(1)) if ep_match else None

                self.episodes.append({
                    'title': title,
                    'ep_number': ep_number,
                    'date': entry.get('published', ''),
                    'url': audio_url
                })
        
        print(f"ğŸ“Š å…±æ‰¾åˆ° {len(self.episodes)} é›†ç¯€ç›®ã€‚")
        return self.episodes

    def download_file(self, url: str, filename: str) -> Optional[str]:
        """ä¸‹è¼‰å–®ä¸€æª”æ¡ˆ (å«é€²åº¦æ¢)"""
        # æ¸…ç†æª”åéæ³•å­—å…ƒ
        safe_filename = re.sub(r'[\\/*?:"<>|]', '', filename).strip()
        file_path = os.path.join(self.save_dir, safe_filename)

        if os.path.exists(file_path):
            print(f"â­ï¸  æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³é: {safe_filename}")
            return file_path

        print(f"â¬‡ï¸  é–‹å§‹ä¸‹è¼‰: {safe_filename}")
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            total_size = int(response.headers.get('content-length', 0))
            
            # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦
            with open(file_path, 'wb') as f, tqdm(
                total=total_size, unit='iB', unit_scale=True, unit_divisor=1024, 
                desc="Progress", leave=False
            ) as bar:
                for data in response.iter_content(chunk_size=1024):
                    size = f.write(data)
                    bar.update(size)
            
            print(f"   âœ… ä¸‹è¼‰å®Œæˆ")
            return file_path
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
            if os.path.exists(file_path):
                os.remove(file_path) # ä¸‹è¼‰å¤±æ•—å‰‡åˆªé™¤æ®˜æª”
            return None

    def download_specific_episodes(self, target_numbers: List[int]):
        """ä¸‹è¼‰æŒ‡å®šé›†æ•¸ (æ‚¨è¦çš„åŠŸèƒ½)"""
        if not self.episodes:
            self.parse_feed()

        print(f"\nğŸ¯ æº–å‚™ä¸‹è¼‰æŒ‡å®šé›†æ•¸: {target_numbers}")
        
        # è½‰æ›æˆ Set åŠ é€Ÿæœå°‹
        targets_set = set(target_numbers)
        
        for ep in self.episodes:
            if ep['ep_number'] in targets_set:
                # æª”åç¯„ä¾‹: EP418_æ¨™é¡Œ.mp3
                # å–å¾—å‰¯æª”å
                ext = ".mp3"
                if "m4a" in ep['url']: ext = ".m4a"
                
                safe_title = ep['title'][:40] # æˆªæ–·æ¨™é¡Œé¿å…éé•·
                filename = f"{safe_title}{ext}"
                
                self.download_file(ep['url'], filename)
                targets_set.remove(ep['ep_number'])

        if targets_set:
            print(f"âš ï¸ æ‰¾ä¸åˆ°ä»¥ä¸‹é›†æ•¸ (å¯èƒ½æœªåœ¨ Feed ä¸­æˆ–æ ¼å¼ä¸ç¬¦): {sorted(list(targets_set))}")

    def download_recent_episodes(self, count: int = 3):
        """ä¸‹è¼‰æœ€æ–° N é›† (Colab æ¸¬è©¦æ–¹ä¾¿ç”¨)"""
        if not self.episodes:
            self.parse_feed()
            
        print(f"\nğŸ†• æº–å‚™ä¸‹è¼‰æœ€æ–° {count} é›†")
        for ep in self.episodes[:count]:
            ext = ".mp3"
            if "m4a" in ep['url']: ext = ".m4a"
            safe_title = ep['title'][:40]
            filename = f"{safe_title}{ext}"
            self.download_file(ep['url'], filename)

# --- 3. ä½¿ç”¨è€…è¨­å®šèˆ‡åŸ·è¡Œå€ ---
if __name__ == "__main__":
    
    # ç¯„ä¾‹ RSS (Open House æ­æœ¬è±ªæ–¯)
    RSS_URL = "https://feed.firstory.me/rss/user/cke0tqspfvlc00803lwhmdb2t"
    
    # å»ºç«‹ä¸‹è¼‰å™¨ (æœƒè‡ªå‹•å­˜åˆ° data/audio/openhouse)
    downloader = PodcastDownloader(RSS_URL, sub_dir="openhouse")
    
    # # === [æ¨¡å¼ A] æŒ‡å®šé›†æ•¸ä¸‹è¼‰ (é‚„åŸæ‚¨çš„éœ€æ±‚) ===
    # # å¡«å…¥æ‚¨æƒ³ä¸‹è¼‰çš„é›†æ•¸è™Ÿç¢¼
    # TARGET_EPS = [418, 414, 408, 396, 392]
    # downloader.download_specific_episodes(TARGET_EPS)
    
    # # === [æ¨¡å¼ B] ä¸‹è¼‰å€é–“ (ä¾‹å¦‚ 400 åˆ° 405) (é¸ç”¨) ===
    # TARGET_EPS = list(range(400, 406)) 
    # downloader.download_specific_episodes(TARGET_EPS)

    # # === [æ¨¡å¼ C] ä¸‹è¼‰æœ€æ–°é›†æ•¸ (é¸ç”¨) ===
    # # å¦‚æœä¸æƒ³æŒ‡å®šï¼Œåªæƒ³æŠ“æœ€æ–°çš„ï¼ŒæŠŠä¸‹é¢è¨»è§£æ‰“é–‹
    downloader.download_recent_episodes(3)
