import os
import time
import json
import sys
from faster_whisper import WhisperModel
from typing import Optional
from tqdm import tqdm  # <--- æ–°å¢ï¼šå¼•å…¥é€²åº¦æ¢å¥—ä»¶

# --- æ–°å¢ï¼šç’°å¢ƒè¨­å®šå€ ---
def detect_environment():
    """åµæ¸¬æ˜¯å¦åœ¨ Colab ç’°å¢ƒ"""
    # 1. æª¢æŸ¥æ˜¯å¦æœ‰ Colab ç‰¹æœ‰çš„ç’°å¢ƒè®Šæ•¸ (é©ç”¨æ–¼ !python è…³æœ¬åŸ·è¡Œ)
    if "COLAB_RELEASE_TAG" in os.environ or "COLAB_GPU" in os.environ:
        return True
    
    # 2. æª¢æŸ¥ sys.modules (é©ç”¨æ–¼ Notebook äº’å‹•æ¨¡å¼)
    if 'google.colab' in sys.modules:
        return True
        
    return False

def get_paths():
    """æ ¹æ“šç’°å¢ƒå›å‚³æ­£ç¢ºçš„å°ˆæ¡ˆæ ¹ç›®éŒ„èˆ‡éŸ³è¨Šè·¯å¾‘"""
    if detect_environment():
        print("â˜ï¸ åµæ¸¬åˆ° Colab ç’°å¢ƒ")
        from google.colab import drive
        # å¼·åˆ¶æ›è¼‰ Google Drive
        if not os.path.exists('/content/drive'):
            drive.mount('/content/drive')
        
        # âš ï¸ æ³¨æ„ï¼šé€™è£¡å‡è¨­æ‚¨å°‡å°ˆæ¡ˆä¸Šå‚³åˆ°äº† Drive çš„ "MyProject/whisper" è³‡æ–™å¤¾
        # è«‹æ ¹æ“šæ‚¨å¯¦éš›çš„ Drive çµæ§‹ä¿®æ”¹é€™è£¡ï¼
        project_root = '/content/drive/MyDrive/MyProject/whisper'
    else:
        print("ğŸ’» åµæ¸¬åˆ°æœ¬åœ°ç’°å¢ƒ")
        # å–å¾—ç›®å‰æª”æ¡ˆ (transcriber.py) çš„ä¸Šä¸€å±¤çš„ä¸Šä¸€å±¤
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

    audio_dir = os.path.join(project_root, "data", "audio")
    return project_root, audio_dir

# --- åŸæœ‰çš„é¡åˆ¥é‚è¼¯ (å¾®èª¿) ---
class PodcastTranscriber:
    def __init__(self, model_size: str = "large-v3", device: str = "auto", compute_type: str = "float16"):
        # 1. å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„ (æˆ‘å€‘ä¹‹å‰å¯«çš„ detect_environment é‚è¼¯æœƒæ±ºå®šé€™æ˜¯æœ¬åœ°é‚„æ˜¯é›²ç«¯è·¯å¾‘)
        project_root, _ = get_paths()
        
        # 2. è¨­å®šæ¨¡å‹å­˜æ”¾è·¯å¾‘ï¼šå­˜åœ¨å°ˆæ¡ˆåº•ä¸‹çš„ "models" è³‡æ–™å¤¾
        # ä¾‹å¦‚åœ¨ Colab ä¸Šæœƒæ˜¯ï¼š/content/drive/MyDrive/MyProject/whisper/models
        model_root = os.path.join(project_root, "models")
        
        # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
        if not os.path.exists(model_root):
            os.makedirs(model_root)

        print(f"ğŸš€ æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹: {model_size} ({device}) | ç²¾åº¦: {compute_type}...")
        print(f"ğŸ“‚ æ¨¡å‹å¿«å–è·¯å¾‘: {model_root}")

        try:
            # 3. é—œéµä¿®æ”¹ï¼šåŠ å…¥ download_root åƒæ•¸
            self.model = WhisperModel(
                model_size, 
                device=device, 
                compute_type=compute_type,
                download_root=model_root  # <--- å°±æ˜¯é€™ä¸€è¡Œï¼
            )
            print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise

    def transcribe_file(self, audio_path: str) -> Optional[str]:
        """
        è½‰éŒ„å–®å€‹éŸ³è¨Šæª”æ¡ˆï¼Œè¼¸å‡º txt å’Œ json
        """
        if not os.path.exists(audio_path):
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {audio_path}")
            return None

        file_name = os.path.basename(audio_path)
        # è¼¸å‡ºè·¯å¾‘æ”¹ç‚ºç›¸å°è·¯å¾‘ï¼Œç¢ºä¿è·Ÿéš¨ audio_path
        output_dir = os.path.join(os.path.dirname(audio_path), "../transcripts")
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        base_name = os.path.splitext(file_name)[0]
        txt_path = os.path.join(output_dir, f"{base_name}.txt")
        json_path = os.path.join(output_dir, f"{base_name}.json")

        # æª¢æŸ¥æ˜¯å¦å·²ç¶“è½‰éŒ„é (é¿å…é‡è¤‡åŸ·è¡Œ)
        if os.path.exists(txt_path) and os.path.exists(json_path):
            print(f"â­ï¸  è·³éå·²è½‰éŒ„æª”æ¡ˆ: {file_name}")
            return txt_path

        print(f"\nğŸ™ï¸  é–‹å§‹è½‰éŒ„: {file_name}")
        start_time = time.time()

        try:
            # 1. å–å¾— segments ç”Ÿæˆå™¨ èˆ‡ éŸ³æª”è³‡è¨Š
            segments, info = self.model.transcribe(
                audio_path, 
                beam_size=5, 
                language="zh", 
                vad_filter=True
            )

            print(f"   â„¹ï¸  èªè¨€: {info.language} (ä¿¡å¿ƒåº¦: {info.language_probability:.2f}) | é•·åº¦: {info.duration:.2f}s")
            
            transcript_data = []
            
            # ä½¿ç”¨ list æš«å­˜ï¼Œæœ€å¾Œä¸€æ¬¡å¯«å…¥ï¼Œæ¸›å°‘ IO (Colab ä¸Š Drive çš„ IO æ¯”è¼ƒæ…¢)
            full_text_lines = []
            
            # å¯«å…¥æª”é ­
            full_text_lines.append(f"ä¾†æº: {file_name}")
            full_text_lines.append(f"æ¨¡å‹: large-v3 | æ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}")
            full_text_lines.append("-" * 50 + "\n")

            # --- 2. ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦æ¢ ---
            # total=info.duration : è¨­å®šé€²åº¦æ¢ç¸½é•·åº¦ç‚ºéŸ³æª”ç§’æ•¸
            # unit='s' : å–®ä½é¡¯ç¤ºç‚ºç§’
            with tqdm(total=round(info.duration, 2), unit='s', desc="   Processing", leave=True) as pbar:
                for i, segment in enumerate(segments, 1):
                    start_m, start_s = divmod(int(segment.start), 60)
                    end_m, end_s = divmod(int(segment.end), 60)
                    time_str = f"[{start_m:02d}:{start_s:02d} -> {end_m:02d}:{end_s:02d}]"
                    text = segment.text.strip()
                    
                    line = f"{time_str} {text}"
                    full_text_lines.append(line)
                    
                    transcript_data.append({
                        "id": i,
                        "start": segment.start,
                        "end": segment.end,
                        "text": text
                    })

                    # æ›´æ–°é€²åº¦æ¢
                    # segment.end æ˜¯ç›®å‰é€™å¥è©±çµæŸçš„æ™‚é–“é»
                    # æˆ‘å€‘å°‡é€²åº¦æ¢æ›´æ–°åˆ°é€™å€‹æ™‚é–“é»
                    pbar.update(segment.end - pbar.n)

            # 3. å¯«å…¥æª”æ¡ˆ
            with open(txt_path, "w", encoding="utf-8") as f:
                f.write("\n".join(full_text_lines))

            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(transcript_data, f, ensure_ascii=False, indent=2)

            duration = time.time() - start_time
            print(f"âœ… å®Œæˆï¼è€—æ™‚: {duration:.2f}s")
            return txt_path

        except Exception as e:
            print(f"âŒ å¤±æ•—: {file_name} - {e}")
            return None

    def transcribe_folder(self, folder_path: str):
        """
        æ‰¹æ¬¡è½‰éŒ„è³‡æ–™å¤¾å…§çš„æ‰€æœ‰éŸ³è¨Šæª”æ¡ˆ
        """
        if not os.path.exists(folder_path):
            print(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")
            return

        # æ”¯æ´çš„éŸ³è¨Šæ ¼å¼
        audio_extensions = ('.mp3', '.m4a', '.wav', '.flac')
        # æ‰¾å‡ºæ‰€æœ‰éŸ³è¨Šæª”
        files = [f for f in os.listdir(folder_path) if f.lower().endswith(audio_extensions)]
        files.sort() # æ’åºï¼Œç¢ºä¿é †åºä¸€è‡´
        
        print(f"\nğŸ“‚ è™•ç†è³‡æ–™å¤¾: {folder_path} (å…± {len(files)} å€‹æª”æ¡ˆ)")
        for f in files:
            self.transcribe_file(os.path.join(folder_path, f))

# --- ä¸»ç¨‹å¼å€ ---
if __name__ == "__main__":
    # 1. è‡ªå‹•å–å¾—è·¯å¾‘
    PROJECT_ROOT, AUDIO_DIR = get_paths()
    
    # 2. è¨­å®šæ¨¡å‹åƒæ•¸
    # å¦‚æœæ˜¯ Colab (æœ‰ GPU)ï¼Œæˆ‘å€‘ç”¨ float16 è·‘æ¯”è¼ƒå¿«ï¼›æœ¬åœ° CPU ç”¨ int8
    is_colab = detect_environment()
    device = "cuda" if is_colab else "cpu"
    compute_type = "float16" if is_colab else "int8"
    
    # 3. åˆå§‹åŒ–è½‰éŒ„å™¨
    transcriber = PodcastTranscriber(
        model_size="large-v3", 
        device=device, 
        compute_type=compute_type
    )
    
    # 4. åŸ·è¡Œè½‰éŒ„
    # é€™è£¡æœƒè‡ªå‹•æƒæ AUDIO_DIR ä¸‹çš„æ‰€æœ‰æª”æ¡ˆ
    transcriber.transcribe_folder(AUDIO_DIR)